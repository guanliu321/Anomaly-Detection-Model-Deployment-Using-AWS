{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and resample",
    "\n",
    "resample the fraud label data, lift the ratio of fraud to non-fraud from 0.1:100 to 1:100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change it to your own path that places credit card fraud dataset.",
    "\n",
    "#file = \"LOCAL_DATA_PATH\"",
    "\n",
    "card = pd.read_csv(file)\n",
    "\n",
    "from math import floor\n",
    "train_size = floor(card.shape[0]*0.8) #the top \"train_size\" rows of data will be used as historical data\n",
    "#used for training model\n",
    "\n",
    "#the rest will be used as incoming test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_card = card.iloc[train_size:,:]\n",
    "test_card_fraud = test_card[test_card['Class']==1]\n",
    "print('testing data rows: ',test_card.shape[0])\n",
    "print('testing fraud data rows: ',test_card_fraud.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsample fraud data\n",
    "test_card_fraud_final = pd.concat([test_card_fraud]*80, ignore_index=True)\n",
    "test_card_final = pd.concat([test_card,test_card_fraud_final], ignore_index=True)\n",
    "test_card_final = test_card_final.iloc[np.random.RandomState(seed=1).permutation(len(test_card_final))]\n",
    "print('testing data rows: ',test_card_final.shape[0])\n",
    "print('testing fraud data rows: ',test_card_fraud_final.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Firehose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import base64\n",
    "\n",
    "class KinesisLoader:\n",
    "    # TODO: create new stream if stream_name doesn't exist\n",
    "    \n",
    "    def __init__(self, client,stream_source,stream_name,batch_size=100,sleep_time = 1):\n",
    "        \"\"\"\n",
    "        The client is a low level boto3 client \n",
    "        The stream_source is a dataset used to simulate streaming data, \n",
    "            each row contains multiple features of a transaction\n",
    "        The stream_name here is the name of the kinesis stream.\n",
    "        The default batch_size here is to match the maximum allowed by Kinesis in a PutRecords request\n",
    "        \"\"\"\n",
    "        self.batch_size = min(batch_size, 100)\n",
    "        self.kinesis_client = client\n",
    "        self.stream_source = stream_source\n",
    "        self.stream_name = stream_name\n",
    "        self.sleep_time = sleep_time\n",
    "    #TODO: partition by timestamp \n",
    "    def submit_batch(self):\n",
    "        count = 0\n",
    "        records_batch = []\n",
    "        for row in range(self.stream_source.shape[0]):\n",
    "            '''\n",
    "            encoding: convert each row to json format, and then to base64 encoded\n",
    "            '''\n",
    "            #base64.b64encode(self.stream_source.iloc[0,:].to_json().encode('utf-8'))\n",
    "            json_row = self.stream_source.iloc[row,:].to_json()\n",
    "            records_batch.append({'Data':json_row})\n",
    "            count+=1\n",
    "            '''\n",
    "            Request syntax of put_record_batch():\n",
    "            {\n",
    "               \"DeliveryStreamName\": \"string\",\n",
    "               \"Records\": [ \n",
    "                    { \n",
    "                     \"Data\": blob\n",
    "                    }\n",
    "               ]\n",
    "            }\n",
    "            '''\n",
    "            if count == self.batch_size or row == self.stream_source.shape[0]-1:\n",
    "                request = {\n",
    "                'Records':records_batch,\n",
    "                'DeliveryStreamName':self.stream_name\n",
    "            }\n",
    "                #print('just sent out one request: {}'.format(request))\n",
    "                self.kinesis_client.put_record_batch(**request)\n",
    "                #self.submit_batch_until_successful(records_batch,response)\n",
    "                count=0\n",
    "                records_batch=[]\n",
    "                time.sleep(self.sleep_time)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client( 'firehose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_client = KinesisLoader(client,test_card_final.iloc[:1000,:],'trendsmarket',\n",
    "                              batch_size=10,sleep_time=0.5)\n",
    "upload_client.submit_batch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
